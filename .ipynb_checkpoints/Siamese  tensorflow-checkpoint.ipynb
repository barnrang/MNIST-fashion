{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper.load_batch as lb\n",
    "import helper.load_music as ld\n",
    "import pygame\n",
    "songs = ld.music_load(dir='Music_sample',length=8000)\n",
    "song_test = songs[0].reshape(-1,2)\n",
    "pygame.mixer.init(44100,-16,2)\n",
    "sound = pygame.sndarray.make_sound(song_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_test = [np.reshape(_,(-1,28,28,1))/255. for _ in [X_train, X_test]]\n",
    "X_val, y_val = X_train[-5000:], y_train[-5000:]\n",
    "X_train, y_train = X_train[:-5000], y_train[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'X_train':X_train,\n",
    "    'X_val':X_val,\n",
    "    'X_test':X_test,\n",
    "    'y_train':y_train,\n",
    "    'y_val':y_val,\n",
    "    'y_test':y_test,\n",
    "    'num_class':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Winit = tf.random_normal_initializer(mean=0,stddev=0.01)\n",
    "binit = tf.random_normal_initializer(mean=0.5,stddev=0.01)\n",
    "Denseinit = tf.random_normal_initializer(mean=0,stddev=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, reg_pow=0.001):\n",
    "    reg = tf.contrib.layers.l2_regularizer(scale=reg_pow)\n",
    "    con = tf.constant_initializer\n",
    "    with tf.variable_scope('conv1'):\n",
    "        X = tf.layers.conv2d(X,32,kernel_size=[2,2],strides=[1,1],activation=tf.nn.relu\n",
    "                     ,kernel_initializer=Winit,bias_initializer=binit,kernel_regularizer=reg)\n",
    "    #X = tf.layers.batch_normalization(X, axis=-1, training=is_training)\n",
    "        X = tf.layers.max_pooling2d(X,[2,2],2)\n",
    "    with tf.variable_scope('conv2'):\n",
    "        X = tf.layers.conv2d(X,128,kernel_size=[2,2],strides=[1,1],activation=tf.nn.relu\n",
    "                        ,kernel_initializer=Winit,bias_initializer=binit,kernel_regularizer=reg)\n",
    "        X = tf.layers.max_pooling2d(X,[2,2],2)\n",
    "        X = tf.contrib.layers.flatten(X)\n",
    "    with tf.variable_scope('full1'):\n",
    "        X = tf.layers.dense(X,512,kernel_initializer=Denseinit,kernel_regularizer=reg,activation=tf.sigmoid)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_predict(X1,X2):\n",
    "    '''\n",
    "    Input\n",
    "    X1,X2: (N,M)\n",
    "    y: (N,) of 1,0 value\n",
    "    Return\n",
    "    loss by distance\n",
    "    '''\n",
    "    dim = X1.get_shape()[1]\n",
    "    alpha = tf.get_variable(dtype=tf.float32,shape=[dim],name='last_dense')\n",
    "    diff = tf.abs(X1-X2)\n",
    "    out = tf.layers.dense(diff * alpha,1,kernel_initializer=Denseinit)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X1 = tf.placeholder(tf.float32,[None,28,28,1])\n",
    "X2 = tf.placeholder(tf.float32,[None,28,28,1])\n",
    "y = tf.placeholder(tf.int32,[None,1])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "with tf.variable_scope('bottleneck') as scope:\n",
    "    Y1 = model(X1)\n",
    "    scope.reuse_variables()\n",
    "    Y2 = model(X2)\n",
    "p = combine_predict(Y1,Y2)\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(y,tf.float32),logits=p)) \\\n",
    "    + tf.reduce_sum(reg_losses)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "predict = tf.cast(tf.greater(p,0.), dtype=tf.int32)\n",
    "correct_pred = tf.equal(predict, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lb.BatchLoader(**data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 28, 28, 1), (8, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1,t2,yt = data.make_batch(4)\n",
    "t1.shape, yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "val_size = 500\n",
    "for i in range(10000):\n",
    "    for phase in ['train','val']:\n",
    "        if phase == 'train':\n",
    "            step = [loss, accuracy, train_step]\n",
    "            first, second, expect = data.make_batch(batch_size, dat_type='train')\n",
    "        else:\n",
    "            step = [loss, accuracy, correct_pred]\n",
    "            first, second, expect = data.make_batch(val_size, dat_type='val')\n",
    "        feed = {X1:first,X2:second,y:expect}\n",
    "        current_loss, acc, _ = sess.run(step, feed_dict=feed)\n",
    "        print('{} loss is {} and accuracy is {}'.format(phase, current_loss, acc))\n",
    "\n",
    "sound.play()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatbot]",
   "language": "python",
   "name": "conda-env-chatbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
